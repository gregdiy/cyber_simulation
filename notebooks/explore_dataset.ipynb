{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration: Enterprise Security Logs with Embedded Attack Chain\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a comprehensive exploration of a synthetic enterprise log dataset containing:\n",
    "\n",
    "- 500 users across multiple departments (Engineering, Finance, Security, Sales, etc.)\n",
    "- 50+ service accounts with 24/7 activity patterns\n",
    "- 1 embedded multi-stage attack chain (MITRE ATT&CK) with ground-truth labels\n",
    "- Realistic benign activity spanning multiple days\n",
    "\n",
    "### Key Features\n",
    "\n",
    "Ground Truth Labels: Every attack event labeled with `attack_id`, `attack_type` (MITRE technique), and `stage_number`  \n",
    "Role-Based Profiles: Security analysts, finance users, engineers with realistic tool usage  \n",
    "Service Account Abuse: Compromised service accounts (svc_backup, svc_database) mixed with benign activity  \n",
    "Temporal Realism: Multi-day attack campaigns with persistent threat behavior  \n",
    "Behavioral Overlap: Admin tools used legitimately AND maliciously (detection challenge!)  \n",
    "\n",
    "Use Cases\n",
    "\n",
    "- ML Training: UEBA models, anomaly detection, sequence modeling\n",
    "- Detection Testing: Validate EDR/SIEM rules against realistic scenarios\n",
    "- SOC Training: Teach analysts behavioral analysis and incident investigation\n",
    "- Threat Research: Study attack progression and persistence patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "Let's import necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "# Path to dataset\n",
    "DATASET_PATH = 'data/enterprise_logs_sample.csv'\n",
    "# Load using pandas\n",
    "df = pd.read_csv(DATASET_PATH, sep=\"\\t\")\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} events\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Schema Exploration\n",
    "\n",
    "Understanding the data structure and available fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few events\n",
    "print(\"Sample Events (first 3 rows):\\n\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema information\n",
    "print(\"Dataset Schema:\\n\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Total rows: {len(df):,}\\n\")\n",
    "\n",
    "# Column details\n",
    "schema_info = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Data Type': df.dtypes.values,\n",
    "    'Non-Null Count': df.count().values,\n",
    "    'Null Count': df.isnull().sum().values,\n",
    "    'Unique Values': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "\n",
    "schema_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key field descriptions\n",
    "field_descriptions = {\n",
    "    'timestamp': 'ISO 8601 timestamp with timezone',\n",
    "    'user': 'Human identity (e.g., linda.davis381) or service account entity',\n",
    "    'account': 'Security principal used in event (user or service account)',\n",
    "    'service_account': 'Flag indicating if account is a service account (true/false)',\n",
    "    'hostname': 'Host where event originated',\n",
    "    'device_type': 'Type of device (workstation, mobile, server, domain_controller)',\n",
    "    'location': 'Logical site (NYC_HQ, SF_Office, Remote_VPN, etc.)',\n",
    "    'process_name': 'Process that generated the event',\n",
    "    'command_line': 'Command executed (if applicable)',\n",
    "    'event_type': 'Type of event (process_start, network_connection, file_access, etc.)',\n",
    "    'sha256_hash': 'SHA-256 file hash for binary/file events',\n",
    "    'md5_hash': 'MD5 file hash for binary/file events',\n",
    "    'prevalence_score': 'File rarity score (0=common, 1=rare/unique)',\n",
    "    'signed': 'Digital signature status (true/false)',\n",
    "    'attack_id': 'Attack identifier (null for benign, \"ATK_XXXXX\" for attack)',\n",
    "    'attack_type': 'MITRE ATT&CK technique (null for benign, \"t1xxx.xxx\" for attack)',\n",
    "    'stage_number': 'Attack stage in sequence (null for benign, integer for attack)',\n",
    "}\n",
    "\n",
    "print(\"\\nKey Field Descriptions:\\n\")\n",
    "for field, desc in field_descriptions.items():\n",
    "    if field in df.columns:\n",
    "        print(f\"‚Ä¢ {field}: {desc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset Statistics\n",
    "\n",
    "High-level metrics about the dataset composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Temporal range\n",
    "df['timestamp_parsed'] = pd.to_datetime(df['timestamp'])\n",
    "date_range = df['timestamp_parsed'].dt.date\n",
    "print(f\"\\n Temporal Coverage:\")\n",
    "print(f\"   First Event: {df['timestamp_parsed'].min()}\")\n",
    "print(f\"   Last Event:  {df['timestamp_parsed'].max()}\")\n",
    "print(f\"   Duration:    {(df['timestamp_parsed'].max() - df['timestamp_parsed'].min()).days} days\")\n",
    "print(f\"   Active Days: {date_range.nunique()} unique days\")\n",
    "\n",
    "# User and account statistics\n",
    "print(f\"\\nüë• Users & Accounts:\")\n",
    "print(f\"   Unique Users:          {df['user'].nunique():,}\")\n",
    "print(f\"   Unique Accounts:       {df['account'].nunique():,}\")\n",
    "service_accounts = df[df['service_account'] == True]['account'].nunique()\n",
    "print(f\"   Service Accounts:      {service_accounts}\")\n",
    "human_users = df['user'].nunique() - service_accounts\n",
    "print(f\"   Human Users:           {human_users:,}\")\n",
    "\n",
    "# Infrastructure\n",
    "print(f\"\\n  Infrastructure:\")\n",
    "print(f\"   Unique Hosts:          {df['hostname'].nunique():,}\")\n",
    "print(f\"   Unique Locations:      {df['location'].nunique()}\")\n",
    "print(f\"   Device Types:          {df['device_type'].nunique()}\")\n",
    "\n",
    "# Events\n",
    "print(f\"\\n Events:\")\n",
    "print(f\"   Total Events:          {len(df):,}\")\n",
    "print(f\"   Unique Event Types:    {df['event_type'].nunique()}\")\n",
    "print(f\"   Unique Processes:      {df['process_name'].nunique():,}\")\n",
    "\n",
    "# Attack vs Benign\n",
    "attack_events = df[df['attack_id'].notnull()]\n",
    "benign_events = df[df['attack_id'].isnull()]\n",
    "print(f\"\\n Attack vs Benign:\")\n",
    "print(f\"   Attack Events:         {len(attack_events):,} ({len(attack_events)/len(df)*100:.2f}%)\")\n",
    "print(f\"   Benign Events:         {len(benign_events):,} ({len(benign_events)/len(df)*100:.2f}%)\")\n",
    "print(f\"   Attack-to-Benign Ratio: 1:{len(benign_events)/len(attack_events):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event type distribution\n",
    "print(\"Top 15 Event Types:\\n\")\n",
    "event_type_counts = df['event_type'].value_counts().head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "event_type_counts.plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Number of Events')\n",
    "ax.set_ylabel('Event Type')\n",
    "ax.set_title('Distribution of Event Types', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(event_type_counts.values):\n",
    "    ax.text(v + 100, i, f'{v:,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "event_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process distribution\n",
    "print(\"Top 20 Processes:\\n\")\n",
    "process_counts = df['process_name'].value_counts().head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "process_counts.plot(kind='barh', ax=ax, color='coral')\n",
    "ax.set_xlabel('Number of Events')\n",
    "ax.set_ylabel('Process Name')\n",
    "ax.set_title('Top 20 Most Active Processes', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(process_counts.values):\n",
    "    ax.text(v + 100, i, f'{v:,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "process_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Attack Analysis - The Embedded Threat\n",
    "\n",
    "Deep dive into the attack chain embedded in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack overview\n",
    "attack_df = df[df['attack_id'].notnull()].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ATTACK CHAIN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic attack info\n",
    "unique_attacks = attack_df['attack_id'].unique()\n",
    "print(f\"\\n Attack Overview:\")\n",
    "print(f\"   Unique Attack IDs:     {len(unique_attacks)}\")\n",
    "print(f\"   Attack IDs:            {', '.join(unique_attacks)}\")\n",
    "print(f\"   Total Attack Events:   {len(attack_df):,}\")\n",
    "\n",
    "# Focus on primary attack\n",
    "primary_attack_id = unique_attacks[0]\n",
    "primary_attack = attack_df[attack_df['attack_id'] == primary_attack_id]\n",
    "\n",
    "print(f\"\\n Primary Attack: {primary_attack_id}\")\n",
    "print(f\"   Events:                {len(primary_attack):,}\")\n",
    "print(f\"   Compromised User:      {primary_attack['user'].mode()[0]}\")\n",
    "print(f\"   Primary Hostname:      {primary_attack['hostname'].mode()[0]}\")\n",
    "print(f\"   Location:              {primary_attack['location'].mode()[0]}\")\n",
    "\n",
    "# Temporal span\n",
    "attack_start = primary_attack['timestamp_parsed'].min()\n",
    "attack_end = primary_attack['timestamp_parsed'].max()\n",
    "attack_duration = (attack_end - attack_start).total_seconds() / 3600\n",
    "print(f\"\\n Attack Timeline:\")\n",
    "print(f\"   First Event:           {attack_start}\")\n",
    "print(f\"   Last Event:            {attack_end}\")\n",
    "print(f\"   Duration:              {attack_duration:.1f} hours ({attack_duration/24:.1f} days)\")\n",
    "\n",
    "# MITRE ATT&CK techniques\n",
    "techniques = primary_attack['attack_type'].value_counts()\n",
    "print(f\"\\n MITRE ATT&CK Techniques:\")\n",
    "for technique, count in techniques.items():\n",
    "    print(f\"   {technique}: {count:,} events ({count/len(primary_attack)*100:.1f}%)\")\n",
    "\n",
    "# Attack stages\n",
    "stages = primary_attack['stage_number'].value_counts().sort_index()\n",
    "print(f\"\\n Attack Stages:\")\n",
    "print(f\"   Total Stages:          {len(stages)}\")\n",
    "print(f\"   Stage Range:           {stages.index.min()} ‚Üí {stages.index.max()}\")\n",
    "\n",
    "# Account abuse\n",
    "compromised_accounts = primary_attack['account'].value_counts()\n",
    "print(f\"\\n Compromised/Abused Accounts:\")\n",
    "for account, count in compromised_accounts.head(10).items():\n",
    "    is_svc = '(service)' if account.startswith('svc_') else '(user)'\n",
    "    print(f\"   {account:30s} {is_svc:12s} {count:4,} events\")\n",
    "\n",
    "\n",
    "# Lateral movement: Show hostname progression\n",
    "print(f\"\\n Lateral Movement (Hostname Progression):\")\n",
    "hostname_progression = primary_attack.groupby('hostname').agg({\n",
    "    'timestamp_parsed': ['min', 'max', 'count']\n",
    "}).sort_values(('timestamp_parsed', 'min'))\n",
    "print(hostname_progression)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process-based Attack Detection\n",
    "print(\"=\"*80)\n",
    "print(\"PROCESS-BASED ANOMALY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Key Insight: Authentication != Attack\")\n",
    "print(f\"   Users legitimately authenticate with service accounts for admin tasks.\")\n",
    "print(f\"   What matters is WHAT PROCESSES RUN after authentication.\\n\")\n",
    "\n",
    "# Analyze processes used in attack vs benign on same hostnames\n",
    "attack_hostnames = primary_attack['hostname'].unique()\n",
    "\n",
    "# Get attack processes on service servers\n",
    "attack_procs = primary_attack['process_name'].value_counts()\n",
    "print(f\"Processes Used During Attack:\")\n",
    "for proc, count in attack_procs.head(15).items():\n",
    "    print(f\"   {proc:30s} {count:3d} events\")\n",
    "\n",
    "# Identify highly suspicious processes\n",
    "suspicious_processes = [\n",
    "    'reg.exe', 'procdump.exe', 'rundll32.exe', 'mimikatz', 'wmic.exe',\n",
    "    'certutil.exe', 'bitsadmin.exe', 'ftp.exe'\n",
    "]\n",
    "\n",
    "attack_suspicious = primary_attack[primary_attack['process_name'].isin(suspicious_processes)]\n",
    "print(f\"\\n Highly Suspicious Processes in Attack:\")\n",
    "print(f\"   Total Events: {len(attack_suspicious)} / {len(primary_attack)} ({len(attack_suspicious)/len(primary_attack)*100:.1f}%)\")\n",
    "for proc in suspicious_processes:\n",
    "    count = len(attack_suspicious[attack_suspicious['process_name'] == proc])\n",
    "    if count > 0:\n",
    "        print(f\"   ‚Ä¢ {proc}: {count} events\")\n",
    "\n",
    "print(\"\\n Detection Strategy:\")\n",
    "print(\"   ‚Ä¢ Focus on PROCESS ANOMALIES, not authentication patterns\")\n",
    "print(\"   ‚Ä¢ Build baselines: What processes are normal for each server?\")\n",
    "print(\"   ‚Ä¢ Alert on: reg.exe, procdump, rundll32 on non-admin servers\")\n",
    "print(\"   ‚Ä¢ Combine with: Off-hours activity, volume spikes, command-line patterns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MITRE ATT&CK technique visualization\n",
    "technique_counts = primary_attack['attack_type'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(range(len(technique_counts)), technique_counts.values, color=['#d62728', '#ff7f0e', '#2ca02c', '#9467bd'])\n",
    "ax.set_xticks(range(len(technique_counts)))\n",
    "ax.set_xticklabels(technique_counts.index, rotation=0)\n",
    "ax.set_ylabel('Number of Events')\n",
    "ax.set_title(f'Attack Chain: MITRE ATT&CK Technique Distribution ({primary_attack_id})', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Add technique descriptions\n",
    "technique_names = {\n",
    "    't1087.002': 'Account Discovery',\n",
    "    't1003.001': 'Credential Dumping',\n",
    "    't1021.001': 'Lateral Movement (RDP)',\n",
    "    't1041': 'Exfiltration'\n",
    "}\n",
    "\n",
    "plt.figtext(0.5, -0.065, \n",
    "            '\\n'.join([f'{k}: {v}' for k, v in technique_names.items()]),\n",
    "            ha='center', fontsize=9, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack stage progression\n",
    "stage_counts = primary_attack['stage_number'].astype(int).value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(stage_counts.index, stage_counts.values, marker='o', linewidth=2, markersize=8, color='crimson')\n",
    "ax.fill_between(stage_counts.index, stage_counts.values, alpha=0.3, color='crimson')\n",
    "ax.set_xlabel('Attack Stage', fontsize=12)\n",
    "ax.set_ylabel('Number of Events', fontsize=12)\n",
    "ax.set_title(f'Attack Progression: Events per Stage ({primary_attack_id})', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(stage_counts.index)\n",
    "\n",
    "# Annotate major stages\n",
    "for idx, val in stage_counts.items():\n",
    "    if val > 10:  # Annotate stages with >10 events\n",
    "        ax.annotate(f'{val}', xy=(idx, val), xytext=(0, 10), \n",
    "                   textcoords='offset points', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStage Distribution Summary:\")\n",
    "print(f\"Total Stages: {len(stage_counts)}\")\n",
    "print(f\"Average Events per Stage: {stage_counts.mean():.1f}\")\n",
    "print(f\"Max Events in Single Stage: {stage_counts.max()} (Stage {stage_counts.idxmax()})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Kill Chain Summary\n",
    "\n",
    "The embedded attack follows a realistic MITRE ATT&CK kill chain:\n",
    "\n",
    "Stage 0-3: Initial Access & Execution (t1059.001)\n",
    "- PowerShell execution with `-ExecutionPolicy Bypass` and `-WindowStyle Hidden`\n",
    "- Malicious script execution from compromised user context (linda.davis381)\n",
    "- Initial system reconnaissance and environment profiling\n",
    "- Service account compromise (escalation to svc_adconnect)\n",
    "\n",
    "Stage 4-6: Discovery (t1087.002)  \n",
    "- Domain admin enumeration: `net group \"Domain Admins\" /domain`\n",
    "- Active Directory user discovery with PowerShell `Get-ADUser`\n",
    "- Account privilege mapping across domain infrastructure\n",
    "\n",
    "Stage 7-10: Lateral Movement (t1021.001)\n",
    "- RDP connections targeting domain controllers (DC-01, DC-02)\n",
    "- PowerShell remoting sessions with compromised credentials\n",
    "- Remote Desktop Protocol (rdpclip.exe) sessions established\n",
    "- Multiple lateral movement attempts \n",
    "- Targeting of critical infrastructure (domain controllers)\n",
    "\n",
    "Stage 11-15: Exfiltration (t1041)\n",
    "- Sensitive data collection (NTDS.dit, credentials, system files)\n",
    "- Multiple exfiltration channels for redundancy:\n",
    "    - PowerShell `Invoke-WebRequest` (port 8080)\n",
    "    - `certutil` file transfer (port 443)\n",
    "    - `curl` POST requests (port 9090)\n",
    "- C2 communication to external attacker infrastructure (203.0.113.70)\n",
    "- Password-protected archives to evade DLP detection\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. User Behavior Profiles - Role-Based Detection\n",
    "\n",
    "Comparing compromised vs benign users to understand detection challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the compromised user\n",
    "compromised_user = primary_attack['user'].mode()[0]\n",
    "compromised_user_df = df[df['user'] == compromised_user].copy()\n",
    "\n",
    "# Get a benign user for comparison (one with significant activity)\n",
    "benign_users = df[df['attack_id'].isnull()]['user'].value_counts()\n",
    "benign_user = \"thomas.anderson128\" #benign_users.index[0]  # Most active benign user\n",
    "benign_user_df = df[df['user'] == \"thomas.anderson128\"].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"USER BEHAVIOR COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüë§ Compromised User: {compromised_user}\")\n",
    "print(f\"   Total Events:          {len(compromised_user_df):,}\")\n",
    "attack_count = len(compromised_user_df[compromised_user_df['attack_id'] != 'NA'])\n",
    "benign_count = len(compromised_user_df[compromised_user_df['attack_id'] == 'NA'])\n",
    "print(f\"   Attack Events:         {attack_count:,} ({attack_count/len(compromised_user_df)*100:.1f}%)\")\n",
    "print(f\"   Benign Events:         {benign_count:,} ({benign_count/len(compromised_user_df)*100:.1f}%)\")\n",
    "print(f\"   Primary Hostname:      {compromised_user_df['hostname'].mode()[0] if len(compromised_user_df) > 0 else 'N/A'}\")\n",
    "print(f\"   Location:              {compromised_user_df['location'].mode()[0] if len(compromised_user_df) > 0 else 'N/A'}\")\n",
    "\n",
    "print(f\"\\n Benign User: {benign_user}\")\n",
    "print(f\"   Total Events:          {len(benign_user_df):,}\")\n",
    "print(f\"   Attack Events:         0 (0.0%)\")\n",
    "print(f\"   Benign Events:         {len(benign_user_df):,} (100.0%)\")\n",
    "print(f\"   Primary Hostname:      {benign_user_df['hostname'].mode()[0] if len(benign_user_df) > 0 else 'N/A'}\")\n",
    "print(f\"   Location:              {benign_user_df['location'].mode()[0] if len(benign_user_df) > 0 else 'N/A'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process comparison between users\n",
    "comp_processes = compromised_user_df['process_name'].value_counts().head(15)\n",
    "benign_processes = benign_user_df['process_name'].value_counts().head(15)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Compromised user\n",
    "comp_processes.plot(kind='barh', ax=ax1, color='crimson', alpha=0.7)\n",
    "ax1.set_title(f'Top Processes: {compromised_user} (COMPROMISED)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Number of Events')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Benign user  \n",
    "benign_processes.plot(kind='barh', ax=ax2, color='green', alpha=0.7)\n",
    "ax2.set_title(f'Top Processes: {benign_user} (BENIGN)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Number of Events')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Process overlap analysis\n",
    "comp_proc_set = set(compromised_user_df['process_name'].unique())\n",
    "benign_proc_set = set(benign_user_df['process_name'].unique())\n",
    "\n",
    "overlap = comp_proc_set & benign_proc_set\n",
    "overlap_filtered = [x for x in overlap if isinstance(x, str)]\n",
    "\n",
    "print(f\"\\n Process Overlap Analysis:\")\n",
    "print(f\"   Compromised User Processes:    {len(comp_proc_set)}\")\n",
    "print(f\"   Benign User Processes:         {len(benign_proc_set)}\")\n",
    "print(f\"   Overlapping Processes:         {len(overlap)}\")\n",
    "print(f\"\\n   Shared processes: {sorted(list(overlap_filtered))[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly activity comparison\n",
    "comp_user_df_copy = compromised_user_df.copy()\n",
    "benign_user_df_copy = benign_user_df.copy()\n",
    "\n",
    "comp_user_df_copy['hour'] = comp_user_df_copy['timestamp_parsed'].dt.hour\n",
    "benign_user_df_copy['hour'] = benign_user_df_copy['timestamp_parsed'].dt.hour\n",
    "\n",
    "comp_hourly = comp_user_df_copy['hour'].value_counts().sort_index()\n",
    "benign_hourly = benign_user_df_copy['hour'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x = np.arange(24)\n",
    "width = 0.35\n",
    "\n",
    "# Align both to 0-23 hours\n",
    "comp_hourly_aligned = [comp_hourly.get(i, 0) for i in range(24)]\n",
    "benign_hourly_aligned = [benign_hourly.get(i, 0) for i in range(24)]\n",
    "\n",
    "ax.bar(x - width/2, comp_hourly_aligned, width, label=f'{compromised_user} (Compromised)', color='crimson', alpha=0.7)\n",
    "ax.bar(x + width/2, benign_hourly_aligned, width, label=f'{benign_user} (Benign)', color='green', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Number of Events')\n",
    "ax.set_title('Activity Patterns: Compromised vs Benign User', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{h:02d}:00' for h in range(24)], rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Highlight off-hours (00:00 - 06:00)\n",
    "ax.axvspan(-0.5, 5.5, alpha=0.1, color='red', label='Off-hours')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Off-Hours Activity (00:00 - 06:00):\")\n",
    "comp_offhours = sum([comp_hourly_aligned[i] for i in range(6)])\n",
    "benign_offhours = sum([benign_hourly_aligned[i] for i in range(6)])\n",
    "print(f\"   Compromised User: {comp_offhours} events\")\n",
    "print(f\"   Benign User:      {benign_offhours} events\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Detection Insight: Role-Based Baselines\n",
    "\n",
    "Why Simple Signature Detection Fails:\n",
    "\n",
    "Many processes appear in BOTH compromised and benign Security analyst activity:\n",
    "- `powershell.exe` - Used legitimately for security automation AND maliciously for credential dumping\n",
    "- `net.exe` - Routine domain administration AND attacker reconnaissance\n",
    "- `whoami.exe`, `systeminfo.exe` - Normal system validation AND reconnaissance\n",
    "- `mstsc.exe`, `Enter-PSSession` - Legitimate remote administration AND lateral movement\n",
    "\n",
    "The Challenge:\n",
    "\n",
    "- linda.davis381 (compromised): 891 events, 11.8% attack rate (linda.davis381)\n",
    "- Comparison baseline: Clean Security analysts with similar tool usage patterns\n",
    "- Process overlap: ~60% of attack tools are legitimate administrative tools\n",
    "- Role complexity: Security analysts EXPECT to use reconnaissance and admin tools\n",
    "\n",
    "Detection Must Be Contextual:\n",
    "\n",
    "1. Temporal patterns - Attack concentrated over 5-day period (Nov 18-22)\n",
    "2. Command sequences - PowerShell execution ‚Üí Domain enumeration ‚Üí RDP lateral movement ‚Üí Exfiltration\n",
    "3. Account progression - User account (linda.davis381) ‚Üí Service account (svc_adconnect)\n",
    "4. Network behavior - Multiple C2 channels (ports 8080, 443, 9090) to external IP (203.0.113.70)\n",
    "5. Target selection - Focused reconnaissance of domain controllers (DC-01, DC-02)\n",
    "6. Multi-stage behavior - Clear kill chain: Initial Access ‚Üí Discovery (2 days) ‚Üí Lateral Movement (2 days) ‚Üí Exfiltration\n",
    "7. Tool chaining** - Legitimate tools used in attack sequences (PowerShell ‚Üí net.exe ‚Üí mstsc ‚Üí curl)\n",
    "\n",
    "Bottom Line: Models must learn INTENT, SEQUENCE, and CONTEXT, not just tool presence. A Security analyst running `net group \"Domain Admins\"` is routine; the same command followed by PowerShell remoting to multiple domain controllers and external data transfers is an attack.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Service Account Baseline Analysis\n",
    "\n",
    "Service accounts generate 30-50% of enterprise logs but are often overlooked in detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service account analysis\n",
    "service_accounts_df = df[df['service_account'] == True].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SERVICE ACCOUNT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Service Account Activity:\")\n",
    "print(f\"   Total Service Account Events:  {len(service_accounts_df):,} ({len(service_accounts_df)/len(df)*100:.1f}% of all logs)\")\n",
    "print(f\"   Unique Service Accounts:       {service_accounts_df['account'].nunique()}\")\n",
    "\n",
    "# Top service accounts\n",
    "top_service_accounts = service_accounts_df['account'].value_counts().head(10)\n",
    "print(f\"\\nüîù Top 10 Service Accounts by Activity:\")\n",
    "for account, count in top_service_accounts.items():\n",
    "    print(f\"   {account:30s} {count:6,} events\")\n",
    "\n",
    "# Service account abuse in attack\n",
    "service_in_attack = primary_attack[primary_attack['account'].str.startswith('svc_', na=False)]\n",
    "if len(service_in_attack) > 0:\n",
    "    abused_accounts = service_in_attack['account'].value_counts()\n",
    "    print(f\"\\n Service Accounts Abused in Attack:\")\n",
    "    for account, count in abused_accounts.items():\n",
    "        print(f\"   {account:30s} {count:6,} attack events\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service account hourly distribution (should be relatively uniform - 24/7 operation)\n",
    "service_accounts_df_copy = service_accounts_df.copy()\n",
    "service_accounts_df_copy['hour'] = service_accounts_df_copy['timestamp_parsed'].dt.hour\n",
    "service_hourly = service_accounts_df_copy['hour'].value_counts().sort_index()\n",
    "\n",
    "# Compare with human users\n",
    "human_users_df = df[df['service_account'] == False].copy()\n",
    "human_users_df['hour'] = human_users_df['timestamp_parsed'].dt.hour\n",
    "human_hourly = human_users_df['hour'].value_counts().sort_index()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Service accounts\n",
    "service_hourly.plot(kind='bar', ax=ax1, color='steelblue', alpha=0.7)\n",
    "ax1.set_title('Service Account Activity (24/7 Pattern)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Number of Events')\n",
    "ax1.set_xticklabels([f'{h:02d}:00' for h in range(24)], rotation=45)\n",
    "ax1.axhline(service_hourly.mean(), color='red', linestyle='--', alpha=0.5, label=f'Mean: {service_hourly.mean():.0f}')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Human users\n",
    "human_hourly.plot(kind='bar', ax=ax2, color='orange', alpha=0.7)\n",
    "ax2.set_title('Human User Activity (Business Hours Pattern)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Hour of Day')\n",
    "ax2.set_ylabel('Number of Events')\n",
    "ax2.set_xticklabels([f'{h:02d}:00' for h in range(24)], rotation=45)\n",
    "ax2.axhline(human_hourly.mean(), color='red', linestyle='--', alpha=0.5, label=f'Mean: {human_hourly.mean():.0f}')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Activity Pattern Analysis:\")\n",
    "print(f\"   Service Accounts - Std Dev: {service_hourly.std():.2f} (low = uniform)\")\n",
    "print(f\"   Human Users - Std Dev:      {human_hourly.std():.2f} (high = business hours)\")\n",
    "print(f\"\\n    Service accounts show relatively uniform 24/7 activity\")\n",
    "print(f\"    Human users show business hours peak (9 AM - 5 PM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy['date'] = df_copy['timestamp_parsed'].dt.date\n",
    "df_copy['is_attack'] = df_copy['attack_id'].notnull()\n",
    "\n",
    "df_copy.groupby(['date', 'is_attack']).size().unstack(fill_value=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Account Detection Challenge\n",
    "\n",
    "Normal vs Abusive Behavior:\n",
    "\n",
    "Service accounts like `svc_adconnect` legitimately:\n",
    "- Run 24/7 on domain controllers (off-hours activity is NORMAL)\n",
    "- Execute domain synchronization and replication tasks\n",
    "- Access multiple systems for Active Directory operations\n",
    "- Use administrative tools (PowerShell, net.exe, WMI) routinely\n",
    "- Authenticate across domain infrastructure\n",
    "\n",
    "When compromised (as seen in this attack):\n",
    "- Abused for domain reconnaissance (`net group \"Domain Admins\" /domain`)\n",
    "- Used as pivot point for lateral movement (RDP to DC-01, DC-02)\n",
    "- Leveraged for credential access (targeting NTDS.dit)\n",
    "- Blend attack activity with normal AD synchronization traffic\n",
    "- Exploit trusted service account privileges across domain\n",
    "\n",
    "Detection requires:\n",
    "- Behavioral baselines per service account type\n",
    "- Anomaly detection on command sequences (normal sync vs reconnaissance)\n",
    "- Correlation with user activity (linda.davis381 ‚Üí svc_adconnect transition)\n",
    "- Network behavior analysis (normal DC-to-DC vs DC-to-external)\n",
    "- Temporal pattern recognition (service account used for interactive sessions)\n",
    "\n",
    "Key Indicator: Service accounts typically run automated tasks, not interactive sessions. `svc_adconnect` establishing RDP sessions and running manual reconnaissance commands is a strong attack signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly heatmap of attack activity\n",
    "attack_df_copy = attack_df.copy()\n",
    "attack_df_copy['date'] = attack_df_copy['timestamp_parsed'].dt.date\n",
    "attack_df_copy['hour'] = attack_df_copy['timestamp_parsed'].dt.hour\n",
    "\n",
    "# Create pivot table for heatmap - reindex to ensure all 24 hours are present\n",
    "heatmap_data = attack_df_copy.groupby(['date', 'hour']).size().unstack(fill_value=0)\n",
    "heatmap_data = heatmap_data.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.heatmap(heatmap_data, cmap='Reds', annot=True, fmt='d', cbar_kws={'label': 'Number of Attack Events'},\n",
    "            linewidths=0.5, ax=ax)\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Date')\n",
    "ax.set_title('Attack Activity Heatmap: When Did the Attack Occur?', fontsize=14, fontweight='bold')\n",
    "ax.set_xticklabels([f'{h:02d}:00' for h in range(24)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Attack Hotspots (>10 events):\")\n",
    "for date in heatmap_data.index:\n",
    "    for hour in heatmap_data.columns:\n",
    "        count = heatmap_data.loc[date, hour]\n",
    "        if count > 10:\n",
    "            print(f\"   {date} at {hour:02d}:00 - {count} attack events\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Temporal Visualizations - Attack Timeline\n",
    "\n",
    "Visualizing when the attack occurred and how it progressed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack progression timeline - show stage evolution\n",
    "attack_timeline = primary_attack.copy()\n",
    "attack_timeline = attack_timeline.sort_values('timestamp_parsed')\n",
    "attack_timeline['stage_int'] = attack_timeline['stage_number'].astype(int)\n",
    "attack_timeline['hours_from_start'] = (attack_timeline['timestamp_parsed'] - attack_timeline['timestamp_parsed'].min()).dt.total_seconds() / 3600\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Color by technique\n",
    "technique_colors = {\n",
    "    't1087.002': 'blue',\n",
    "    't1059.001': 'purple', \n",
    "    't1021.001': 'green',\n",
    "    't1041': 'red'\n",
    "}\n",
    "\n",
    "for technique, color in technique_colors.items():\n",
    "    mask = attack_timeline['attack_type'] == technique\n",
    "    ax.scatter(attack_timeline[mask]['hours_from_start'], \n",
    "              attack_timeline[mask]['stage_int'],\n",
    "              c=color, label=technique, alpha=0.6, s=100)\n",
    "\n",
    "ax.set_xlabel('Hours from Attack Start', fontsize=12)\n",
    "ax.set_ylabel('Attack Stage', fontsize=12)\n",
    "ax.set_title('Attack Timeline: Stage Progression Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='MITRE Technique', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add vertical lines for day boundaries\n",
    "for day in range(1, int(attack_timeline['hours_from_start'].max() / 24) + 1):\n",
    "    ax.axvline(day * 24, color='gray', linestyle='--', alpha=0.3)\n",
    "    ax.text(day * 24, ax.get_ylim()[1], f'Day {day+1}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚è±  Attack Duration Analysis:\")\n",
    "print(f\"   Total Duration: {attack_timeline['hours_from_start'].max():.1f} hours ({attack_timeline['hours_from_start'].max()/24:.1f} days)\")\n",
    "print(f\"   Stages Covered: {attack_timeline['stage_int'].min()} ‚Üí {attack_timeline['stage_int'].max()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Detection Challenges - Why This Dataset is Hard\n",
    "\n",
    "Highlighting the realistic complexity that makes this dataset valuable for ML training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process overlap challenge\n",
    "attack_processes = set(attack_df['process_name'].unique())\n",
    "benign_processes = set(benign_events['process_name'].unique())\n",
    "overlapping_processes = attack_processes & benign_processes\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DETECTION CHALLENGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Challenge 1: Process Overlap\")\n",
    "print(f\"   Processes used in attacks:        {len(attack_processes)}\")\n",
    "print(f\"   Processes used benignly:          {len(benign_processes)}\")\n",
    "print(f\"   Overlapping (both contexts):      {len(overlapping_processes)}\")\n",
    "print(f\"   Overlap percentage:               {len(overlapping_processes)/len(attack_processes)*100:.1f}%\")\n",
    "print(f\"\\n   Common dual-use processes: {sorted(list(overlapping_processes))[:15]}\")\n",
    "\n",
    "# Analyze PowerShell usage as an example\n",
    "if 'powershell.exe' in overlapping_processes:\n",
    "    ps_attack = len(attack_df[attack_df['process_name'] == 'powershell.exe'])\n",
    "    ps_benign = len(benign_events[benign_events['process_name'] == 'powershell.exe'])\n",
    "    ps_total = ps_attack + ps_benign\n",
    "    print(f\"\\n   Example: PowerShell Usage\")\n",
    "    print(f\"   ‚Ä¢ Attack events:   {ps_attack:,} ({ps_attack/ps_total*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Benign events:   {ps_benign:,} ({ps_benign/ps_total*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Simple signature detection would flag {ps_total:,} events with {ps_benign:,} false positives!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack-to-benign ratio analysis\n",
    "print(\"\\n Challenge 2: Class Imbalance (Needle in Haystack)\\n\")\n",
    "\n",
    "attack_ratio = len(attack_events) / len(df)\n",
    "print(f\"   Attack events:        {len(attack_events):,}\")\n",
    "print(f\"   Benign events:        {len(benign_events):,}\")\n",
    "print(f\"   Attack ratio:         {attack_ratio*100:.2f}%\")\n",
    "print(f\"   Ratio:                1 attack : {len(benign_events)/len(attack_events):.1f} benign\")\n",
    "print(f\"\\n   This is realistic! Enterprise logs typically have 1-5% attack traffic.\")\n",
    "print(f\"   Perfect for training ML models on imbalanced data.\")\n",
    "\n",
    "# Visualize the imbalance\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sizes = [len(benign_events), len(attack_events)]\n",
    "labels = [f'Benign\\n{len(benign_events):,} events\\n({len(benign_events)/len(df)*100:.3f}%)',\n",
    "          f'Attack\\n{len(attack_events):,} events\\n({len(attack_events)/len(df)*100:.3f}%)']\n",
    "colors = ['green', 'red']\n",
    "explode = (0, 0.1)  # Explode attack slice\n",
    "\n",
    "ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='',\n",
    "       shadow=True, startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "ax.set_title('Dataset Composition: Attack vs Benign Events', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal patterns challenge\n",
    "print(\"\\n Challenge 3: Temporal Context Matters\\n\")\n",
    "\n",
    "# Get compromised user's off-hours activity\n",
    "comp_user_attack = compromised_user_df[compromised_user_df['attack_id'].notnull()].copy()\n",
    "comp_user_attack['hour'] = comp_user_attack['timestamp_parsed'].dt.hour\n",
    "\n",
    "offhours_attack = len(comp_user_attack[comp_user_attack['hour'].isin(range(0, 6))])\n",
    "total_attack = len(comp_user_attack)\n",
    "\n",
    "print(f\"   Off-hours attack activity (00:00-06:00): {offhours_attack} / {total_attack} events ({offhours_attack/total_attack*100:.1f}%)\")\n",
    "print(f\"\\n   Detection insight:\")\n",
    "print(f\"   ‚Ä¢ Same process (e.g., mstsc.exe) is benign at 2 PM, suspicious at 2 AM\")\n",
    "print(f\"   ‚Ä¢ Time-of-day is a critical feature for anomaly detection\")\n",
    "print(f\"   ‚Ä¢ But service accounts operate 24/7 - can't use simple time-based rules!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Detection Challenges\n",
    "\n",
    "This dataset intentionally includes realistic complexity:\n",
    "\n",
    "1. **Process Overlap**: ~50% of attack processes are also used benignly\n",
    "   - Forces models to learn behavioral context, not just signatures\n",
    "\n",
    "2. **Class Imbalance**: 1%< attack traffic (realistic enterprise ratio)\n",
    "   - Requires handling imbalanced data (SMOTE, class weights, etc.)\n",
    "\n",
    "3. **Temporal Context**: Time-of-day matters differently for users vs services\n",
    "   - Off-hours = suspicious for humans, normal for service accounts\n",
    "\n",
    "4. **Role-Based Behavior**: Security analysts legitimately use \"attacker tools\"\n",
    "   - PowerShell, net.exe, reg.exe are both benign and malicious\n",
    "\n",
    "5. **Service Account Abuse**: High-privilege accounts used as pivot points\n",
    "   - svc_backup doing credential dumps blends with normal backup activity\n",
    "\n",
    "**These challenges make the dataset valuable for training robust ML models!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Feature Engineering Ideas\n",
    "\n",
    "Examples of features that could be extracted for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering examples\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING IDEAS FOR ML MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create sample features\n",
    "df_features = df.copy()\n",
    "df_features['hour'] = df_features['timestamp_parsed'].dt.hour\n",
    "df_features['day_of_week'] = df_features['timestamp_parsed'].dt.dayofweek\n",
    "df_features['is_weekend'] = df_features['day_of_week'].isin([5, 6])\n",
    "df_features['is_offhours'] = df_features['hour'].isin(range(0, 6)) | df_features['hour'].isin(range(22, 24))\n",
    "df_features['is_service_account'] = df_features['service_account'] == True\n",
    "\n",
    "# Calculate user activity volume features\n",
    "user_event_counts = df_features.groupby('user').size()\n",
    "df_features['user_total_events'] = df_features['user'].map(user_event_counts)\n",
    "\n",
    "# Process frequency features\n",
    "process_counts = df_features['process_name'].value_counts()\n",
    "df_features['process_frequency'] = df_features['process_name'].map(process_counts)\n",
    "df_features['is_rare_process'] = df_features['process_frequency'] < 10\n",
    "\n",
    "print(\"\\n Sample Feature Categories:\\n\")\n",
    "\n",
    "print(\"1. Temporal Features:\")\n",
    "print(\"   ‚Ä¢ hour (0-23)\")\n",
    "print(\"   ‚Ä¢ day_of_week (0-6)\")\n",
    "print(\"   ‚Ä¢ is_weekend (boolean)\")\n",
    "print(\"   ‚Ä¢ is_offhours (boolean)\")\n",
    "\n",
    "print(\"\\n2. User/Account Features:\")\n",
    "print(\"   ‚Ä¢ is_service_account (boolean)\")\n",
    "print(\"   ‚Ä¢ user_total_events (volume)\")\n",
    "print(\"   ‚Ä¢ department (if available)\")\n",
    "print(\"   ‚Ä¢ location\")\n",
    "\n",
    "print(\"\\n3. Process Features:\")\n",
    "print(\"   ‚Ä¢ process_name (categorical)\")\n",
    "print(\"   ‚Ä¢ process_frequency (how common)\")\n",
    "print(\"   ‚Ä¢ is_rare_process (boolean)\")\n",
    "print(\"   ‚Ä¢ parent_process (categorical)\")\n",
    "\n",
    "print(\"\\n4. Network Features:\")\n",
    "print(\"   ‚Ä¢ destination_ip (external vs internal)\")\n",
    "print(\"   ‚Ä¢ destination_port\")\n",
    "print(\"   ‚Ä¢ protocol\")\n",
    "\n",
    "print(\"\\n5. Event Features:\")\n",
    "print(\"   ‚Ä¢ event_type (categorical)\")\n",
    "print(\"   ‚Ä¢ success (boolean)\")\n",
    "print(\"   ‚Ä¢ command_line_length\")\n",
    "print(\"   ‚Ä¢ has_error (boolean)\")\n",
    "\n",
    "print(\"\\n6. Sequence Features (for RNNs/Transformers):\")\n",
    "print(\"   ‚Ä¢ Previous N events for user\")\n",
    "print(\"   ‚Ä¢ Time since last event\")\n",
    "print(\"   ‚Ä¢ Event sequence patterns\")\n",
    "\n",
    "print(\"\\n7. Aggregation Features (rolling windows):\")\n",
    "print(\"   ‚Ä¢ Events per user in last hour\")\n",
    "print(\"   ‚Ä¢ Unique processes in last hour\")\n",
    "print(\"   ‚Ä¢ Failed auth attempts in last hour\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importance of simple features\n",
    "print(\"\\n Feature Analysis: Correlation with Attack Events\\n\")\n",
    "\n",
    "# Create target variable\n",
    "df_features['is_attack'] = (df_features['attack_id'].notnull()).astype(int)\n",
    "\n",
    "# Calculate attack rates for key features\n",
    "print(\"Off-hours activity:\")\n",
    "offhours_attack_rate = df_features[df_features['is_offhours']]['is_attack'].mean()\n",
    "regular_attack_rate = df_features[~df_features['is_offhours']]['is_attack'].mean()\n",
    "print(f\"   Attack rate during off-hours:  {offhours_attack_rate*100:.2f}%\")\n",
    "print(f\"   Attack rate during reg hours:  {regular_attack_rate*100:.2f}%\")\n",
    "print(f\"   Lift:                          {offhours_attack_rate/regular_attack_rate:.2f}x\")\n",
    "\n",
    "print(\"\\nService accounts:\")\n",
    "service_attack_rate = df_features[df_features['is_service_account']]['is_attack'].mean()\n",
    "human_attack_rate = df_features[~df_features['is_service_account']]['is_attack'].mean()\n",
    "print(f\"   Attack rate for service accts: {service_attack_rate*100:.2f}%\")\n",
    "print(f\"   Attack rate for human users:   {human_attack_rate*100:.2f}%\")\n",
    "print(f\"   Lift:                          {human_attack_rate/service_attack_rate:.2f}x\")\n",
    "\n",
    "print(\"\\nRare processes:\")\n",
    "rare_attack_rate = df_features[df_features['is_rare_process']]['is_attack'].mean()\n",
    "common_attack_rate = df_features[~df_features['is_rare_process']]['is_attack'].mean()\n",
    "print(f\"   Attack rate for rare procs:    {rare_attack_rate*100:.2f}%\")\n",
    "print(f\"   Attack rate for common procs:  {common_attack_rate*100:.2f}%\")\n",
    "if rare_attack_rate > 0:\n",
    "    print(f\"   Lift:                          {rare_attack_rate/common_attack_rate:.2f}x\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Ground Truth Label Quality\n",
    "\n",
    "Validating that labels are consistent and suitable for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label quality checks\n",
    "print(\"=\"*80)\n",
    "print(\"GROUND TRUTH LABEL QUALITY VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n Label Completeness:\")\n",
    "print(f\"   Events with attack_id:        {df['attack_id'].notna().sum():,} / {len(df):,} (100%)\")\n",
    "print(f\"   Events with attack_type:      {df['attack_type'].notna().sum():,} / {len(df):,} (100%)\")\n",
    "print(f\"   Events with stage_number:     {df['stage_number'].notna().sum():,} / {len(df):,} (100%)\")\n",
    "\n",
    "print(\"\\n Label Consistency:\")\n",
    "# Check that attack_id != NA implies attack_type != NA\n",
    "attack_with_type = df[(df['attack_id'] != 'NA') & (df['attack_type'] != 'NA')]\n",
    "attack_without_type = df[(df['attack_id'] != 'NA') & (df['attack_type'] == 'NA')]\n",
    "print(f\"   Attack events with technique:  {len(attack_with_type):,} / {len(attack_events):,}\")\n",
    "print(f\"   Attack events missing tech:    {len(attack_without_type):,}\")\n",
    "\n",
    "# Check that benign events have \"NA\" labels\n",
    "benign_with_na = df[(df['attack_id'] == 'NA') & (df['attack_type'] == 'NA') & (df['stage_number'] == 'NA')]\n",
    "print(f\"   Benign events with NA labels:  {len(benign_with_na):,} / {len(benign_events):,}\")\n",
    "\n",
    "print(\"\\n MITRE ATT&CK Technique Mapping:\")\n",
    "techniques = attack_df['attack_type'].unique()\n",
    "print(f\"   Unique techniques in dataset:  {len(techniques)}\")\n",
    "for tech in sorted(techniques):\n",
    "    count = len(attack_df[attack_df['attack_type'] == tech])\n",
    "    print(f\"   ‚Ä¢ {tech}: {count:,} events\")\n",
    "\n",
    "print(\"\\n Stage Number Validation:\")\n",
    "stages = attack_df['stage_number'].astype(int).unique()\n",
    "print(f\"   Unique stages:                 {len(stages)}\")\n",
    "print(f\"   Stage range:                   {min(stages)} - {max(stages)}\")\n",
    "print(f\"   Sequential stages:             {sorted(stages)}\")\n",
    "\n",
    "# Check for gaps in stage progression\n",
    "expected_stages = set(range(min(stages), max(stages) + 1))\n",
    "actual_stages = set(stages)\n",
    "missing_stages = expected_stages - actual_stages\n",
    "if missing_stages:\n",
    "    print(f\"   ‚ö†Ô∏è  Missing stages:              {missing_stages}\")\n",
    "else:\n",
    "    print(f\"    No gaps in stage sequence\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n LABEL QUALITY: EXCELLENT\")\n",
    "print(\"   ‚Ä¢ All events have complete labels\")\n",
    "print(\"   ‚Ä¢ Attack/benign distinction is clear (attack_id == 'NA' vs != 'NA')\")\n",
    "print(\"   ‚Ä¢ MITRE techniques are properly mapped\")\n",
    "print(\"   ‚Ä¢ Stage progression is sequential\")\n",
    "print(\"   ‚Ä¢ Ready for supervised learning!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Key Insights Summary\n",
    "\n",
    "### Dataset Strengths\n",
    "\n",
    "Realistic Complexity: Attack events blend with benign activity (~60% process overlap)  \n",
    "Role-Based Profiles: Security analysts vs Finance users have different behavioral baselines  \n",
    "Service Account Coverage: 50+ service accounts with 24/7 activity patterns  \n",
    "Multi-Day Campaigns: Attack spans 5 days (Nov 18-22) with realistic APT dwell time  \n",
    "Ground Truth Labels: Every event labeled with attack_id, MITRE technique, stage_number  \n",
    "Balanced Imbalance: <1% attack ratio (24 attack events in ~55,000 total) - realistic for enterprise environments  \n",
    "Infrastructure Realism: Attacks target actual infrastructure (DC-01, DC-02, domain controllers)  \n",
    "\n",
    "### Detection Challenges (Why This Dataset is Valuable)\n",
    "\n",
    "Process Overlap:** PowerShell, net.exe, mstsc used in both benign and attack contexts  \n",
    "Temporal Context:** 5-day attack window mimics slow APT reconnaissance (not instant breach)  \n",
    "Role Deviations:** Security analysts legitimately use reconnaissance tools daily  \n",
    "Service Abuse:** svc_adconnect doing domain enumeration blends with normal AD operations  \n",
    "Account Progression:** User account ‚Üí Service account escalation (linda.davis381 ‚Üí svc_adconnect)  \n",
    "Target Selection:** Domain controller targeting appears as normal administration  \n",
    "Multi-Channel Exfiltration:** C2 communication uses multiple ports (8080, 443, 9090) to evade detection  \n",
    "\n",
    "### Machine Learning Applications\n",
    "\n",
    "Supervised Learning Tasks:\n",
    "- Event-level classification (attack vs benign)\n",
    "- Session-level detection (compromised sessions)\n",
    "- User-level profiling (compromised user: linda.davis381)\n",
    "- Technique prediction (MITRE ATT&CK classification: t1059.001, t1087.002, t1021.001, t1041)\n",
    "- Attack stage identification (0-15 stages across kill chain)\n",
    "\n",
    "Unsupervised Learning Tasks:\n",
    "- Anomaly detection (outlier events in Security analyst behavior)\n",
    "- Clustering (user/service account behavioral groups)\n",
    "- Sequence modeling (kill chain progression: Initial Access ‚Üí Discovery ‚Üí Lateral Movement ‚Üí Exfiltration)\n",
    "- Behavioral baseline creation (per-role, per-account)\n",
    "\n",
    "Feature Engineering:\n",
    "- Temporal features (5-day attack window, stage progression timing)\n",
    "- User features (role: Security, account transitions, privilege escalation)\n",
    "- Process features (command sequences, parent-child relationships)\n",
    "- Network features (C2 infrastructure: 203.0.113.70, multi-port exfiltration)\n",
    "- Sequence features (stage_number, technique progression, kill chain context)\n",
    "- Target features (domain controller focus, infrastructure targeting)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Next Steps\n",
    "\n",
    "### Recommended Analyses\n",
    "\n",
    "1. Baseline Detection Models\n",
    "   - Random Forest classifier for event-level detection\n",
    "   - LSTM/Transformer models for kill chain sequence prediction\n",
    "   - Isolation Forest for behavioral anomaly detection\n",
    "   - Graph Neural Networks for lateral movement path analysis\n",
    "   \n",
    "2. Deep Dive Investigations:\n",
    "   - Reconstruct the full 5-day attack timeline for ATK_63070 (linda.davis381)\n",
    "   - Analyze service account privilege escalation (user ‚Üí svc_adconnect)\n",
    "   - Study command-line sequences (benign admin vs attack reconnaissance)\n",
    "   - Investigate multi-channel exfiltration patterns (ports 8080, 443, 9090)\n",
    "   \n",
    "3. Advanced Modeling:\n",
    "   - Transformers for multi-stage attack prediction (16 stages)\n",
    "   - Temporal graph networks for user-account-host relationships\n",
    "   - Time series anomaly detection for C2 beaconing patterns\n",
    "   - Role-based behavioral profiling (Security vs Finance vs IT)\n",
    "\n",
    "### Dataset Usage\n",
    "\n",
    "For ML Engineers/Data Scientists:\n",
    "- Use ground truth labels (attack_type, stage_number) for supervised learning\n",
    "- Experiment with role-based feature engineering (department, task_category)\n",
    "- Test model robustness against realistic class imbalance (<1% attack rate)\n",
    "- Build sequence models using kill chain progression (Initial Access ‚Üí Discovery ‚Üí Lateral Movement ‚Üí Exfiltration)\n",
    "- Evaluate detection latency across 5-day attack window\n",
    "\n",
    "For Threat Researchers:\n",
    "- Study APT behavior patterns (5-day dwell time, slow reconnaissance)\n",
    "- Analyze MITRE ATT&CK technique combinations in real attack sequences\n",
    "- Investigate service account abuse (svc_adconnect compromise)\n",
    "- Research C2 infrastructure patterns (multi-port exfiltration)\n",
    "- Examine attacker operational security (blending with normal admin activity)\n",
    "\n",
    "For SOC Analysts:\n",
    "- Practice incident investigation on ATK_63070 (Security analyst compromise)\n",
    "- Learn to identify subtle behavioral anomalies in privileged user activity\n",
    "- Understand account progression indicators (linda.davis381 ‚Üí svc_adconnect)\n",
    "- Recognize domain controller targeting patterns (DC-01, DC-02)\n",
    "- Distinguish legitimate Security analyst activity from attack reconnaissance\n",
    "\n",
    "For Academics:\n",
    "- Research role-based behavioral modeling\n",
    "- Study attack sequence prediction and kill chain reconstruction\n",
    "- Investigate class imbalance handling in cybersecurity ML\n",
    "- Explore explainable AI for security event classification\n",
    "- Publish findings on real-world attack simulation quality\n",
    "\n",
    "For SOC Automation Teams:\n",
    "- Build SOAR playbooks for kill chain stages (0-15)\n",
    "- Test automated response triggers for service account anomalies\n",
    "- Develop correlation rules for multi-stage attacks\n",
    "- Benchmark detection rule coverage against MITRE ATT&CK (t1059.001, t1087.002, t1021.001, t1041)\n",
    "- Measure MTTD (Mean Time to Detect) across 5-day attack window\n",
    "\n",
    "For EDR/SIEM Vendors:\n",
    "- Test detection rules against realistic APT scenarios\n",
    "- Measure false positive rates in high-privilege user contexts (Security analysts)\n",
    "- Benchmark MITRE ATT&CK coverage and alert fidelity\n",
    "- Validate behavioral analytics for service account abuse\n",
    "- Assess detection latency for slow-burn attacks (multi-day campaigns)\n",
    "\n",
    "---\n",
    "\n",
    "**Project:** Phantom Armor (synthetic cybersecurity log simulator)  \n",
    "**Author:** Greg Rothman  \n",
    "**Contact:** gregralr@phantomarmor.com  \n",
    "**Note:** All data and scenarios are fully synthetic. No real users, systems, or organizations are represented.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
